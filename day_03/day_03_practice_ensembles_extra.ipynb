{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_digits as load\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "<h1 align=\"center\">Bagging</h1> \n",
    "\n",
    "** Вопросы для самоконтроля**\n",
    "* Зачем нужно строить композиции над алгоритмами?\n",
    "* Что такое bootstrap-выборка?\n",
    "* Какие бывают варианты построения композиций N базовых алгоритмов классификации?\n",
    "* Что такое Bagging?\n",
    "* Почему работает Bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/bootstrap.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Важно! **\n",
    "    - Бутстрепная выборка имеет такой же размер, что и исходная\n",
    "    - Генерация с повторениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$a_{Bagging}(x) = \\frac{1}{M}\\sum_{i=1}^M a_i(x)$$\n",
    "\n",
    "$a_i(x)$ - обучен на бутстреп-выборке $X^i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/bagging.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "f = X.shape[1]\n",
    "\n",
    "rnd_d3 = DecisionTreeClassifier(max_features=int(f ** 0.5)) # Решающее дерево с рандомизацией в сплитах\n",
    "d3 = DecisionTreeClassifier() # Обычное решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество классификации одним решающим деревом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Decision tree: {cross_val_score(d3, X, y).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество бэггинга над решающими деревьями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bagging: {cross_val_score(BaggingClassifier(d3), X, y).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Какой недостаток есть у деревьев?\n",
    "- Как bagging борется с этим недостатком?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как можно улучшить качество?\n",
    "    - При построении каждого узла отбирать случайные max_features признаков и искать информативное разбиение только по одному из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Randomized Bagging: {cross_val_score(BaggingClassifier(rnd_d3), X, y).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Алгоритм построения случайного леса из $N$ деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого $n = 1..N$:\n",
    "\n",
    "Сгенерировать выборку $X_n$ с помощью бутстрэпа;\n",
    "Построить решающее дерево $b_n$ по выборке $X_n$:\n",
    "* по заданному критерию мы выбираем лучший признак, делаем разбиение в дереве по нему и так до исчерпания выборки\n",
    "* дерево строится, пока в каждом листе не более $n_{min}$ объектов или пока не достигнем определенной высоты дерева\n",
    "* при каждом разбиении сначала выбирается $m$ случайных признаков из $n$ исходных, и оптимальное разделение выборки ищется только среди них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый классификатор:\n",
    "    $$ a(x) = \\dfrac{1}{N} \\sum_{i=1}^{N} b_i(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m$ советуют выбирать равным:\n",
    "- $\\sqrt{n}$ для классификации\n",
    "- $\\dfrac{n}{3}$ для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный список параметров случайного леса для задачи регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class sklearn.ensemble.RandomForestRegressor(\n",
    "    n_estimators — число деревьев в \"лесу\" (по дефолту – 10)\n",
    "    criterion — функция, которая измеряет качество разбиения ветки дерева (по дефолту — \"mse\" , так же можно выбрать \"mae\")\n",
    "    max_features — число признаков, по которым ищется разбиение. Вы можете указать конкретное число или процент признаков, либо выбрать из доступных значений: \"auto\" (все признаки), \"sqrt\", \"log2\". По дефолту стоит \"auto\".\n",
    "    max_depth — максимальная глубина дерева  (по дефолту глубина не ограничена)\n",
    "    min_samples_split — минимальное количество объектов, необходимое для разделения внутреннего узла. Можно задать числом или процентом от общего числа объектов (по дефолту — 2)\n",
    "    min_samples_leaf — минимальное число объектов в листе. Можно задать числом или процентом от общего числа объектов (по дефолту — 1)\n",
    "    min_weight_fraction_leaf — минимальная взвешенная доля от общей суммы весов (всех входных объектов) должна быть в листе (по дефолту имеют одинаковый вес)\n",
    "    max_leaf_nodes — максимальное количество листьев (по дефолту нет ограничения)\n",
    "    min_impurity_split — порог для остановки наращивания дерева (по дефолту 1е-7)\n",
    "    bootstrap — применять ли бустрэп для построения дерева (по дефолту True)\n",
    "    oob_score — использовать ли out-of-bag объекты для оценки R^2 (по дефолту False)\n",
    "    n_jobs — количество ядер для построения модели и предсказаний (по дефолту 1, если поставить -1, то будут использоваться все ядра)\n",
    "    random_state — начальное значение для генерации случайных чисел (по дефолту его нет, если хотите воспроизводимые результаты, то нужно указать любое число типа int\n",
    "    verbose — вывод логов по построению деревьев (по дефолту 0)\n",
    "    warm_start — использует уже натренированую модель и добавляет деревьев в ансамбль (по дефолту False)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи классификации все почти то же самое, мы приведем только те параметры, которыми RandomForestClassifier отличается от RandomForestRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class sklearn.ensemble.RandomForestClassifier(\n",
    "    criterion — поскольку у нас теперь задача классификации, то по дефолту выбран критерий \"gini\" (можно выбрать \"entropy\")\n",
    "    class_weight — вес каждого класса (по дефолту все веса равны 1, но можно передать словарь с весами, либо явно указать \"balanced\", тогда веса классов будут равны их исходным частям в генеральной совокупности; также можно указать \"balanced_subsample\", тогда веса на каждой подвыборке будут меняться в зависимости от распределения классов на этой подвыборке.\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "При построениии модели в первую очередь стоит обратить внимание на следующие параметры:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators — число деревьев в \"лесу\"\n",
    "- criterion — критерий для разбиения выборки в вершине\n",
    "- max_features — число признаков, по которым ищется разбиение\n",
    "- min_samples_leaf — минимальное число объектов в листе\n",
    "- max_depth — максимальная глубина дерева\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение RandomForest на реальной задаче (предсказание оттока клиентов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные можно взять тут: https://github.com/Yorko/mlcourse_open/blob/master/data/telecom_churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/telecom_churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "df = pd.read_csv(\"telecom_churn.csv\")\n",
    "\n",
    "# Выбираем сначала только колонки с числовым типом данных\n",
    "cols = []\n",
    "for i in df.columns:\n",
    "    if (df[i].dtype == \"float64\") or (df[i].dtype == 'int64'):\n",
    "        cols.append(i)\n",
    "\n",
    "# Разделяем на признаки и объекты\n",
    "X, y = df[cols].copy(), np.asarray(df[\"Churn\"],dtype='int8')\n",
    "\n",
    "# Инициализируем страифицированную разбивку нашего датасета для валидации\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Инициализируем наш классификатор с дефолтными параметрами\n",
    "rfc = RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# Обучаем на тренировочном датасете\n",
    "results = cross_val_score(rfc, X, y, cv=skf)\n",
    "\n",
    "# Оцениваем долю верных ответов на тестовом датасете\n",
    "print(f\"CV accuracy score: {100 * results.mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшим этот результат: посмотрим, как ведут себя кривые валидации при изменении основных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем валидацию\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [5, 10, 15, 20, 30, 50, 75, 100]\n",
    "}\n",
    "gscv = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=1,\n",
    "    cv=skf,\n",
    "    return_train_score=True\n",
    ")\n",
    "gscv.fit(X, y)\n",
    "\n",
    "train_acc_mean = gscv.cv_results_[\"mean_train_score\"]\n",
    "test_acc_mean = gscv.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "train_acc_std = gscv.cv_results_[\"std_train_score\"]\n",
    "test_acc_std = gscv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "best_test_acc = gscv.best_score_\n",
    "best_param_value = list(gscv.best_params_.values())[0]\n",
    "print(f\"Best CV accuracy is {100 * best_test_acc:.2f}%\"\n",
    "      f\"with {best_param_value} trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "trees_grid = param_grid[\"n_estimators\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(trees_grid, train_acc_mean, alpha=0.5, color='blue', label='train')\n",
    "ax.plot(trees_grid, test_acc_mean, alpha=0.5, color='red', label='cv')\n",
    "ax.fill_between(trees_grid, test_acc_mean - test_acc_std, test_acc_mean + test_acc_std, color='#888888', alpha=0.4)\n",
    "ax.fill_between(trees_grid, test_acc_mean - 2*test_acc_std, test_acc_mean + 2*test_acc_std, color='#888888', alpha=0.2)\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylim([0.88,1.02])\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"N_estimators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем параметр max_depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, 9, 11, 13, 15, 17, 20, 22, 24]\n",
    "}\n",
    "gscv = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=1,\n",
    "    cv=skf,\n",
    "    return_train_score=True\n",
    ")\n",
    "gscv.fit(X, y)\n",
    "\n",
    "train_acc_mean = gscv.cv_results_[\"mean_train_score\"]\n",
    "test_acc_mean = gscv.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "train_acc_std = gscv.cv_results_[\"std_train_score\"]\n",
    "test_acc_std = gscv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "best_test_acc = gscv.best_score_\n",
    "best_param_value = list(gscv.best_params_.values())[0]\n",
    "print(f\"Best CV accuracy is {100 * best_test_acc:.2f}% \"\n",
    "      f\"with max depth of {best_param_value} trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_grid = param_grid[\"max_depth\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(trees_grid, train_acc_mean, alpha=0.5, color='blue', label='train')\n",
    "ax.plot(trees_grid, test_acc_mean, alpha=0.5, color='red', label='cv')\n",
    "ax.fill_between(trees_grid, test_acc_mean - test_acc_std, test_acc_mean + test_acc_std, color='#888888', alpha=0.4)\n",
    "ax.fill_between(trees_grid, test_acc_mean - 2*test_acc_std, test_acc_mean + 2*test_acc_std, color='#888888', alpha=0.2)\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylim([0.88,1.02])\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Max_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр max_depth хорошо справляется с регуляризацией модели, и мы уже не так сильно переобучаемся. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр min_samples_leaf также выполняет функцию регуляризатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\n",
    "    \"min_samples_leaf\": [1, 3, 5, 7, 9, 11, 13, 15, 17, 20, 22, 24]\n",
    "}\n",
    "gscv = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=1,\n",
    "    cv=skf,\n",
    "    return_train_score=True\n",
    ")\n",
    "gscv.fit(X, y)\n",
    "\n",
    "train_acc_mean = gscv.cv_results_[\"mean_train_score\"]\n",
    "test_acc_mean = gscv.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "train_acc_std = gscv.cv_results_[\"std_train_score\"]\n",
    "test_acc_std = gscv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "best_test_acc = gscv.best_score_\n",
    "best_param_value = list(gscv.best_params_.values())[0]\n",
    "print(f\"Best CV accuracy is {100 * best_test_acc:.2f}% \"\n",
    "      f\"with min samples per leaf of {best_param_value} trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_grid = param_grid[\"min_samples_leaf\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(trees_grid, train_acc_mean, alpha=0.5, color='blue', label='train')\n",
    "ax.plot(trees_grid, test_acc_mean, alpha=0.5, color='red', label='cv')\n",
    "ax.fill_between(trees_grid, test_acc_mean - test_acc_std, test_acc_mean + test_acc_std, color='#888888', alpha=0.4)\n",
    "ax.fill_between(trees_grid, test_acc_mean - 2*test_acc_std, test_acc_mean + 2*test_acc_std, color='#888888', alpha=0.2)\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylim([0.88,1.02])\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Min_samples_leaf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим такой параметр как max_features. Для задач классификации по умолчанию используется $\\sqrt{n}$, где $n$ — число признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\n",
    "    \"max_features\": [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "}\n",
    "gscv = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=1,\n",
    "    cv=skf,\n",
    "    return_train_score=True\n",
    ")\n",
    "gscv.fit(X, y)\n",
    "\n",
    "train_acc_mean = gscv.cv_results_[\"mean_train_score\"]\n",
    "test_acc_mean = gscv.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "train_acc_std = gscv.cv_results_[\"std_train_score\"]\n",
    "test_acc_std = gscv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "best_test_acc = gscv.best_score_\n",
    "best_param_value = list(gscv.best_params_.values())[0]\n",
    "print(f\"Best CV accuracy is {100 * best_test_acc:.2f}% \"\n",
    "      f\"with max features of {best_param_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_grid = param_grid[\"max_features\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(trees_grid, train_acc_mean, alpha=0.5, color='blue', label='train')\n",
    "ax.plot(trees_grid, test_acc_mean, alpha=0.5, color='red', label='cv')\n",
    "ax.fill_between(trees_grid, test_acc_mean - test_acc_std, test_acc_mean + test_acc_std, color='#888888', alpha=0.4)\n",
    "ax.fill_between(trees_grid, test_acc_mean - 2*test_acc_std, test_acc_mean + 2*test_acc_std, color='#888888', alpha=0.2)\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylim([0.88,1.02])\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Max_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае оптимальное число признаков - 4, если судить по кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, итоговый перебор параметров будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем инициализацию параметров, по которым хотим сделать полный перебор\n",
    "parameters = {\n",
    "    \"max_features\": [4, 7, 10, 13],\n",
    "    \"min_samples_leaf\": [1, 3, 5, 7],\n",
    "    \"max_depth\": [5,10,15,20]\n",
    "}\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42, \n",
    "                             n_jobs=-1, oob_score=True, return_train_score=True)\n",
    "gcv = GridSearchCV(rfc, parameters, n_jobs=-1, cv=skf, verbose=1)\n",
    "gcv.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Есть ли переобучение с увеличением числа деревьев?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print(f\"n_estimators = {n_estimators:5d}, train_acc = {train_acc:.4f} test_acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=7), n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print(f\"n_estimators = {n_estimators:5d}, train_acc = {train_acc:.4f} test_acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=14), n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print(f\"n_estimators = {n_estimators:5d}, train_acc = {train_acc:.4f} test_acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for n_estimators in [10, 40, 100, 200, 600, 1000]:\n",
    "    clf = RandomForestClassifier(max_depth=14, n_estimators=n_estimators, n_jobs=4)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    train_acc, test_acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "    print(f\"n_estimators = {n_estimators:5d}, train_acc = {train_acc:.4f} test_acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-bag error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/oob.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача** Покажите, что примерно 37% примеров остаются вне выборки бутстрэпа и не используются при построении k-го дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение** Пусть в выборке $l$ объектов. На каждом шаге все объекты попадают в подвыборку с возвращением равновероятно, т.е отдельный объект — с вероятностью $\\dfrac{1}{l}$. Вероятность того, что объект НЕ попадет в подвыборку (т.е. его не взяли $l$ раз): $(1-\\dfrac{1}{l})^l$\n",
    "\n",
    "\n",
    "$$\\lim_{l \\rightarrow +\\infty} (1-\\dfrac{1}{l})^l = \\dfrac{1}{e}$$\n",
    "\n",
    "Тогда вероятность попадания конкретного объекта в подвыборку $1 - \\dfrac{1}{e} \\approx 63\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-Bag оценка — это усредненная оценка базовых алгоритмов на тех ~37% данных, на которых они не обучались.\n",
    "\n",
    "В случае с scikit-learn имплементацией, OOB-оценка точности (accuracy) доступна в поле класса `.oob_score_` объекта класса `RandomForestClassifier(**params)`.\n",
    "OOB ошибка в таком случае будет равна `1 - clf.oob_score_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Выводы</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Bagging**:\n",
    "- Одна из лучших техник для построения алгоритмов ML\n",
    "- Линейно уменьшает разброс и не уменьшает смещение (если не коррелированы ответы базовых алоритмов) \n",
    "- Слабое переобучение\n",
    "- НО переобучение ЕСТЬ -- от сложности одного алгоритма, лучше все же немного обрезать деревья\n",
    "\n",
    "**Random Forest**\n",
    "\n",
    "Плюсы:\n",
    "- имеет высокую точность предсказания, на большинстве задач будет лучше линейных алгоритмов; точность сравнима с точностью бустинга\n",
    "- практически не чувствителен к выбросам в данных из-за случайного сэмлирования\n",
    "- не чувствителен к масштабированию (и вообще к любым монотонным преобразованиям) значений признаков, связано с выбором случайных подпространств\n",
    "- не требует тщательной настройки параметров, хорошо работает «из коробки». С помощью «тюнинга» параметров можно достичь прироста от 0.5 до 3% точности в зависимости от задачи и данных\n",
    "- способен эффективно обрабатывать данные с большим числом признаков и классов\n",
    "- одинаково хорошо обрабатывет как непрерывные, так и дискретные признаки\n",
    "- редко переобучается, на практике добавление деревьев почти всегда только улучшает композицию, но на валидации, после достижения определенного количества деревьев, кривая обучения выходит на асимптоту\n",
    "- хорошо работает с пропусками в данных\n",
    "- предполагает возможность сбалансировать вес каждого класса на всей выборке, либо на подвыборке каждого дерева\n",
    "- вычисляет близость между парами объектов, которые могут использоваться при кластеризации, обнаружении выбросов или (путем масштабирования) дают интересные представления данных\n",
    "- высокая параллелизуемость и масштабируемость\n",
    "\n",
    "Минусы:\n",
    "- в отличие от одного дерева, результаты случайного леса сложнее интерпретировать\n",
    "- алгоритм работает хуже многих линейных методов, когда в выборке очень много разреженных признаков (тексты, Bag of words)\n",
    "- случайный лес не умеет экстраполировать, в отличие от той же линейной регрессии\n",
    "- алгоритм склонен к переобучению на некоторых задачах, особенно на зашумленных данных\n",
    "- для данных, включающих категориальные переменные с различным количеством уровней, случайные леса предвзяты в пользу признаков с большим количеством уровней: когда у признака много уровней, дерево будет сильнее подстраиваться именно под эти признаки, так как на них можно получить более высокое значение оптимизируемого функционала (например, прироста информации)\n",
    "- больший размер получающихся моделей. Требуется $O(NK)$ памяти для хранения модели, где $K$ — число деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
