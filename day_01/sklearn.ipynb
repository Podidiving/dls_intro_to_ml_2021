{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар. Библиотека sklearn\n",
    "В этом семинаре мы научимся решать простейшую задачу машинного обучения на примере датасета <a href=\"https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021\">World Happiness Report 2021</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных\n",
    "Нас интересует файл world-happiness-report-2021 по <a href=\"https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021?select=world-happiness-report-2021.csv\">ссылке</a>. Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('https://www.dropbox.com/s/qe604sk62jxh5pb/world_happiness_report_2021.csv?dl=1')\n",
    "\n",
    "#raw_data = pd.read_csv(\"world_happiness_report_2021.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшая обработка данных (выкидываем ненужные колонки), назначаем новый индекс и т.д.\n",
    "\n",
    "Целевая переменная датасета называется Ladder score. Это средний показатель счастья респондентов, сгруппированный по стране. Остальные данные (кроме регионального показателя) являются числовыми данными, которые мы будем использовать для предсказания счастья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[['Country name', 'Regional indicator', 'Ladder score', 'Logged GDP per capita', \n",
    "             'Social support', 'Healthy life expectancy', 'Freedom to make life choices', \n",
    "             'Generosity', 'Perceptions of corruption']]\n",
    "\n",
    "raw_data.index = raw_data['Country name']\n",
    "raw_data = raw_data.drop(columns='Country name') #delete column country name\n",
    "raw_data = raw_data.sort_values('Ladder score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Всего {len(raw_data)} стран')\n",
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предварительный анализ данных\n",
    "\n",
    "### Задание \n",
    "Постройте гистограмму целевой переменной. Используйте ``pandasDataFrame.hist``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Ladder score'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание \n",
    "Постройте матрицу корреляций целевой переменной с признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(raw_data.corr(), annot=True, cmap='coolwarm',\n",
    "            vmin=-1, vmax=1, annot_kws={\"size\": 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание \n",
    "Найдите в списке Россию и выведите её <strike>товарищей по несчастью</strike> соседей по счастью "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(149)[raw_data.index == 'Russia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_idx = #YOUR CODE: найдите номер России в таблице\n",
    "#YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных, разбиение на train и test, нормировка данных\n",
    "Для наглядности мы будем решать задачу классификации, а не регрессии. Предварительно поделим все страны на \"счастливые\" и \"несчастные\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#перемешаем данные для надёжности\n",
    "data = raw_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "Сформируйте матрицу объекты-признаки, выкинув целевую переменную, а также переменную Regional Indicator (она категориальная, и мы не будем с ней заморачиваться).\n",
    "\n",
    "Выделите в целевую переменную 1, если показатель счастья больше некоторой константы, и 0, иначе. В качестве константы возьмите порог 5.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Regional indicator', 'Ladder score'])\n",
    "y = (data['Ladder score'] > 5.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "Разбейте данные на train и test в пропорции 70:30. Используйте функцию  ``sklearn.model_selection.train_test_split``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "Отнормируйте матрицу объекты-признаки. Найдите нормировочные коэффициенты по обучающей выборке, примените их к тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Самый главный момент: обучение и предсказание\n",
    "### Задание\n",
    "Создайте модель $k$ ближайших соседей при $k = 5$. Обучите её на ``X_train_scaled`` (метод ``.fit``) и предскажите ответы на ``y_train`` и ``y_test`` (метод ``predict``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не менее важный момент: измерение результатов\n",
    "### Задание\n",
    "Посчитайте качество (процент угаданных ответов) на обучающей и тестовой выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Качество на обучающей выборке: {train_accuracy}')\n",
    "print(f'Качество на тестовой выборке: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус: кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация\n",
    "Иногда просто разбиение на обучающую и тестовую выборки не даёт точного прогноза оценки ошибки, ведь обученный алгоритм может сильно меняться в зависимости от обучающей выборки. Чтобы нивелировать эффект конкретной обучающей выборки, используют так называему кросс-валидацию. Идея кросс-валидации состоит в том, чтобы разбить все данные на несколько одинаковых по размеру частей, поочерёдно используя каждую часть как test, а оставшийся датасет --- как train. На каждом из экспериментов вычисляют тестовую ошибку, затем результат усредняют по всем экспериментам.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1cS2AoSrcG5sCGbnKhkv3ZYqKSmtPd-XM)\n",
    "\n",
    "Выполним эту схему на нашем датасете. Кросс-валидация находится в модуле sklearn.model_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "result = cross_val_score(estimator=KNeighborsClassifier(n_neighbors=5), X=X_train_scaled, y=y_train, \n",
    "                         scoring='accuracy', cv=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найдем наилучший параметр с помощью кросс-валидации с перебором по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid_search = GridSearchCV(KNeighborsClassifier(), \n",
    "                               [{'n_neighbors': np.arange(1, 25, 2)}],\n",
    "                               cv=5,\n",
    "                               scoring='accuracy',\n",
    "                               verbose=10)\n",
    "\n",
    "results = gbr_grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(1, 25, 2), results.cv_results_['mean_test_score'], label='mean test score')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('score')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
